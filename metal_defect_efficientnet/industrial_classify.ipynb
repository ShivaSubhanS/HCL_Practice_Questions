{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ea739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPUs available: {len(gpus)}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU found, using CPU\")\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_CLASSES = 6 \n",
    "\n",
    "TRAIN_DIR = \"/mnt/d/code/hcl/NEU-DET/train/images\"\n",
    "VAL_DIR = \"/mnt/d/code/hcl/NEU-DET/validation/images\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "print(f\"\\nDataset Summary:\")\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {val_generator.samples}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "def build_efficientnet_model(num_classes, img_size=224):\n",
    "    base_model = EfficientNetB3(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(img_size, img_size, 3)\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "    inputs = keras.Input(shape=(img_size, img_size, 3))\n",
    "    x = layers.RandomFlip(\"horizontal_and_vertical\")(inputs)\n",
    "    x = layers.RandomRotation(0.1)(x)\n",
    "    x = base_model(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "print(\"\\nBuilding EfficientNet-B3 model...\")\n",
    "model, base_model = build_efficientnet_model(NUM_CLASSES, IMG_SIZE)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.AdamW(learning_rate=LEARNING_RATE, weight_decay=0.01),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=2, name='top_2_accuracy')]\n",
    ")\n",
    "\n",
    "print(\"\\nModel Architecture:\")\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        'best_efficientnet_model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    TensorBoard(\n",
    "        log_dir=f'logs/fit/{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}',\n",
    "        histogram_freq=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Phase 1: Training custom head (base model frozen)\")\n",
    "history_phase1 = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "print(\"Phase 2: Fine-tuning entire model\")\n",
    "base_model.trainable = True\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.AdamW(learning_rate=LEARNING_RATE/10, weight_decay=0.01),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=2, name='top_2_accuracy')]\n",
    ")\n",
    "\n",
    "history_phase2 = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS - 20,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    "    initial_epoch=20\n",
    ")\n",
    "\n",
    "history = {\n",
    "    'accuracy': history_phase1.history['accuracy'] + history_phase2.history['accuracy'],\n",
    "    'val_accuracy': history_phase1.history['val_accuracy'] + history_phase2.history['val_accuracy'],\n",
    "    'loss': history_phase1.history['loss'] + history_phase2.history['loss'],\n",
    "    'val_loss': history_phase1.history['val_loss'] + history_phase2.history['val_loss']\n",
    "}\n",
    "\n",
    "\n",
    "print(\"Loading best model for evaluation...\")\n",
    "\n",
    "best_model = keras.models.load_model('best_efficientnet_model.h5')\n",
    "\n",
    "val_loss, val_accuracy, val_top2_acc = best_model.evaluate(val_generator, verbose=1)\n",
    "print(f\"\\nBest Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"st Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"p-2 Accuracy: {val_top2_acc*100:.2f}%\")\n",
    "\n",
    "print(\"\\nGenerating predictions...\")\n",
    "val_generator.reset()\n",
    "predictions = best_model.predict(val_generator, verbose=1)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true = val_generator.classes\n",
    "\n",
    "\n",
    "print(\"Classification Report\")\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
    "\n",
    "\n",
    "print(\"Per-Class Accuracy\")\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1) * 100\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"{class_name:20s}: {per_class_acc[i]:.2f}%\")\n",
    "\n",
    "def plot_training_history(history):\n",
    "    _, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    epochs_range = range(1, len(history['accuracy']) + 1)\n",
    "    \n",
    "    ax1.plot(epochs_range, history['accuracy'], 'b-o', label='Train Accuracy', markersize=4)\n",
    "    ax1.plot(epochs_range, history['val_accuracy'], 'r-s', label='Val Accuracy', markersize=4)\n",
    "    ax1.axvline(x=20, color='green', linestyle='--', label='Fine-tuning starts', alpha=0.7)\n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.set_ylabel('Accuracy', fontsize=12)\n",
    "    ax1.set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2.plot(epochs_range, history['loss'], 'b-o', label='Train Loss', markersize=4)\n",
    "    ax2.plot(epochs_range, history['val_loss'], 'r-s', label='Val Loss', markersize=4)\n",
    "    ax2.axvline(x=20, color='green', linestyle='--', label='Fine-tuning starts', alpha=0.7)\n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('Loss', fontsize=12)\n",
    "    ax2.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"\\naining history saved as 'training_history.png'\")\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    plt.title('Confusion Matrix', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"nfusion matrix saved as 'confusion_matrix.png'\")\n",
    "\n",
    "plot_training_history(history)\n",
    "plot_confusion_matrix(cm, class_names)\n",
    "\n",
    "\n",
    "print(\"Saving model in multiple formats...\")\n",
    "\n",
    "\n",
    "best_model.save('best_efficientnet_model_saved', save_format='tf')\n",
    "print(\"del saved in SavedModel format: 'best_efficientnet_model_saved/'\")\n",
    "\n",
    "print(\"del saved in HDF5 format: 'best_efficientnet_model.h5'\")\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(best_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "with open('best_efficientnet_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "print(\"del saved in TFLite format: 'best_efficientnet_model.tflite'\")\n",
    "\n",
    "\n",
    "print(\"Training Complete!\")\n",
    "\n",
    "print(\"st model saved in multiple formats\")\n",
    "print(\"ning history saved as 'training_history.png'\")\n",
    "print(\"nfusion matrix saved as 'confusion_matrix.png'\")\n",
    "print(\"orBoard logs saved in 'logs/' directory\")\n",
    "print(f\"\\nFinal Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
    "\n",
    "def load_and_predict(image_path, model_path='best_efficientnet_model.h5'):\n",
    "    model = keras.models.load_model(model_path)\n",
    "    \n",
    "    img = keras.preprocessing.image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = img_array / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = class_names[np.argmax(predictions[0])]\n",
    "    confidence = np.max(predictions[0]) * 100\n",
    "    \n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "    print(f\"Confidence: {confidence:.2f}%\")\n",
    "    \n",
    "    return predicted_class, confidence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
