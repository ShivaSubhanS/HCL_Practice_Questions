{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23de8457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=5)\n",
    "print(\"CV accuracy:\", scores.mean().round(3), \"+/-\", scores.std().round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f1b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "X = X / 255.0\n",
    "y = y.astype(\"int\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000, solver=\"lbfgs\", multi_class=\"multinomial\", n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred).round(4))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fb7b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing.data, housing.target  \n",
    "feature_names = housing.feature_names\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "medinc_idx = feature_names.index(\"MedInc\")\n",
    "X_train_simple = X_train[:, [medinc_idx]]\n",
    "X_test_simple  = X_test[:, [medinc_idx]]\n",
    "\n",
    "simple_model = LinearRegression()\n",
    "simple_model.fit(X_train_simple, y_train)\n",
    "y_pred_simple = simple_model.predict(X_test_simple)\n",
    "\n",
    "multi_model = LinearRegression()\n",
    "multi_model.fit(X_train, y_train)\n",
    "y_pred_multi = multi_model.predict(X_test)\n",
    "\n",
    "print(\"Simple LR — MAE:\", mean_absolute_error(y_test, y_pred_simple).round(3),\n",
    "      \"| R^2:\", r2_score(y_test, y_pred_simple).round(3))\n",
    "print(\"Multiple LR — MAE:\", mean_absolute_error(y_test, y_pred_multi).round(3),\n",
    "      \"| R^2:\", r2_score(y_test, y_pred_multi).round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92fb2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"stocks.csv\", parse_dates=[\"Date\"])\n",
    "df = df.sort_values(\"Date\")\n",
    "\n",
    "for lag in range(1, 6):\n",
    "    df[f\"lag_{lag}\"] = df[\"Close\"].shift(lag)\n",
    "\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "X = df[[f\"lag_{i}\" for i in range(1, 6)]]\n",
    "y = df[\"Close\"]\n",
    "\n",
    "X_train, X_test = X[:-60], X[-60:]\n",
    "y_train, y_test = y[:-60], y[-60:]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Linear Regression MAE:\", round(mae, 3))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(df[\"Date\"].iloc[-60:], y_test, label=\"Actual\")\n",
    "plt.plot(df[\"Date\"].iloc[-60:], y_pred, label=\"Predicted\")\n",
    "plt.title(\"Stock Price Forecast (Linear Regression)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c34576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "n = 5000\n",
    "humidity = rng.uniform(10, 100, n)\n",
    "pressure = rng.uniform(980, 1030, n)\n",
    "wind = rng.uniform(0, 20, n)\n",
    "cloud = rng.uniform(0, 100, n)\n",
    "\n",
    "temp = 30 - 0.2*humidity + 0.03*(pressure-1000) - 0.1*wind + 0.05*cloud + rng.normal(0, 1, n)\n",
    "precip = np.clip(0.02*humidity + 0.01*cloud - 0.3*wind + rng.normal(0, 0.5, n), 0, None)\n",
    "\n",
    "X = np.column_stack([humidity, pressure, wind, cloud])\n",
    "Y = np.column_stack([temp, precip])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = MultiOutputRegressor(RandomForestRegressor(random_state=42))\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "mae_temp = mean_absolute_error(y_test[:,0], pred[:,0])\n",
    "mae_prec = mean_absolute_error(y_test[:,1], pred[:,1])\n",
    "print(\"MAE Temperature:\", round(mae_temp, 3))\n",
    "print(\"MAE Precipitation:\", round(mae_prec, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff38872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "pipe.fit(X_tr, y_tr)\n",
    "y_pred = pipe.predict(X_te)\n",
    "print(classification_report(y_te, y_pred, target_names=data.target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee99b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "n_customers = 1000\n",
    "recency = rng.gamma(shape=2.0, scale=10.0, size=n_customers) * 10\n",
    "frequency = rng.gamma(shape=2.0, scale=2.0, size=n_customers)\n",
    "monetary = rng.lognormal(mean=3.5, sigma=0.7, size=n_customers)\n",
    "\n",
    "df = pd.DataFrame({\"Recency\": recency, \"Frequency\": frequency, \"Monetary\": monetary})\n",
    "\n",
    "X = StandardScaler().fit_transform(df)\n",
    "kmeans = KMeans(n_clusters=5, n_init=20, random_state=42)\n",
    "labels = kmeans.fit_predict(X)\n",
    "\n",
    "df[\"Segment\"] = labels\n",
    "print(df.groupby(\"Segment\").agg({\"Recency\":\"median\", \"Frequency\":\"median\", \"Monetary\":\"median\"}).sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a6fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "grid = np.array([\n",
    "    [3,0,1,0,0,0],\n",
    "    [0,0,1,0,1,0],\n",
    "    [1,0,0,0,1,0],\n",
    "    [0,1,1,0,0,0],\n",
    "    [0,0,0,1,0,2],\n",
    "])\n",
    "\n",
    "start = tuple(np.argwhere(grid==3)[0])\n",
    "goal  = tuple(np.argwhere(grid==2)[0])\n",
    "n_rows, n_cols = grid.shape\n",
    "\n",
    "actions = [(0,1),(0,-1),(1,0),(-1,0)]  \n",
    "n_actions = len(actions)\n",
    "\n",
    "def step(state, action_idx):\n",
    "    r, c = state\n",
    "    dr, dc = actions[action_idx]\n",
    "    nr, nc = r+dr, c+dc\n",
    "    if not (0 <= nr < n_rows and 0 <= nc < n_cols):  \n",
    "        return state, -1, False\n",
    "    if grid[nr, nc] == 1: \n",
    "        return state, -1, False\n",
    "    if (nr, nc) == goal:\n",
    "        return (nr, nc), 10, True\n",
    "    return (nr, nc), -0.04, False  \n",
    "\n",
    "alpha = 0.1\n",
    "gamma = 0.95\n",
    "epsilon = 1.0\n",
    "epsilon_min = 0.05\n",
    "epsilon_decay = 0.995\n",
    "episodes = 2000\n",
    "Q = np.zeros((n_rows, n_cols, n_actions))\n",
    "\n",
    "def choose_action(state):\n",
    "    if random.random() < epsilon:\n",
    "        return random.randrange(n_actions)\n",
    "    r, c = state\n",
    "    return int(np.argmax(Q[r, c]))\n",
    "\n",
    "for ep in range(episodes):\n",
    "    state = start\n",
    "    done = False\n",
    "    while not done:\n",
    "        a = choose_action(state)\n",
    "        next_state, reward, done = step(state, a)\n",
    "        r, c = state\n",
    "        nr, nc = next_state\n",
    "        Q[r, c, a] += alpha * (reward + gamma * np.max(Q[nr, nc]) - Q[r, c, a])\n",
    "        state = next_state\n",
    "    epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
    "\n",
    "state = start\n",
    "path = [state]\n",
    "visited = set([state])\n",
    "for _ in range(200):\n",
    "    r, c = state\n",
    "    a = int(np.argmax(Q[r, c]))\n",
    "    state, _, done = step(state, a)\n",
    "    if state in visited:\n",
    "        break\n",
    "    visited.add(state)\n",
    "    path.append(state)\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "print(\"Start:\", start, \"| Goal:\", goal)\n",
    "print(\"Path length:\", len(path))\n",
    "print(\"Path:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c45fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "titanic = fetch_openml(\"titanic\", version=1, as_frame=True)\n",
    "df = titanic.frame\n",
    "\n",
    "target = \"survived\"\n",
    "features = [\"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\", \"embarked\"]\n",
    "df = df[features + [target]].copy()\n",
    "df[target] = df[target].astype(int)\n",
    "\n",
    "num_features = [\"age\", \"sibsp\", \"parch\", \"fare\"]\n",
    "cat_features = [\"pclass\", \"sex\", \"embarked\"]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_features),\n",
    "        (\"cat\", categorical_transformer, cat_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e1ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(\"spam.csv\")\n",
    "except FileNotFoundError:\n",
    "    df = pd.DataFrame({\n",
    "        \"text\": [\n",
    "            \"Congratulations! You've won a free lottery. Call now!\",\n",
    "            \"Meeting at 10am tomorrow. Please confirm.\",\n",
    "            \"URGENT! Your account is compromised. Click the link to verify.\",\n",
    "            \"Are we still on for lunch today?\"\n",
    "        ],\n",
    "        \"label\": [\"spam\",\"ham\",\"spam\",\"ham\"]\n",
    "    })\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"], df[\"label\"], test_size=0.2, random_state=42, stratify=df[\"label\"]\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2), min_df=2)),\n",
    "    (\"clf\", MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
